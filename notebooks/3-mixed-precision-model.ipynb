{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/nightly/cu102/torch_nightly.html\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cu102/torch-1.6.0.dev20200527-cp37-cp37m-linux_x86_64.whl (812.8 MB)\n",
      "\u001b[K     |██████████████████████▊         | 577.4 MB 66.9 MB/s eta 0:00:0436.5 MB/s eta 0:00:09     |████████████████▋               | 422.7 MB 93.8 MB/s eta 0:00:05     |██████████████████              | 459.6 MB 107.4 MB/s eta 0:00:04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 812.8 MB 6.3 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cu102/torchvision-0.7.0.dev20200527-cp37-cp37m-linux_x86_64.whl (6.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.7 MB 97.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.7/dist-packages (from torch) (0.18.2)\n",
      "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from torch) (1.16.4)\n",
      "Requirement already satisfied, skipping upgrade: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
      "Installing collected packages: torch, torchvision\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.4.0\n",
      "    Uninstalling torch-1.4.0:\n",
      "      Successfully uninstalled torch-1.4.0\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.5.0\n",
      "    Uninstalling torchvision-0.5.0:\n",
      "      Successfully uninstalled torchvision-0.5.0\n",
      "Successfully installed torch-1.6.0.dev20200527 torchvision-0.7.0.dev20200527\n"
     ]
    }
   ],
   "source": [
    "!pip install -U --pre torch torchvision -f https://download.pytorch.org/whl/nightly/cu102/torch_nightly.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorboard\n",
      "  Downloading tensorboard-2.2.1-py3-none-any.whl (3.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0 MB 4.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (3.2.2)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.29.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (46.4.0)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.16.4)\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.9.0)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (3.12.1)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.6.0.post3-py3-none-any.whl (777 kB)\n",
      "\u001b[K     |████████████████████████████████| 777 kB 40.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.15.0)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.15.0-py2.py3-none-any.whl (89 kB)\n",
      "\u001b[K     |████████████████████████████████| 89 kB 15.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.1-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (2.23.0)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.34.2)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard) (1.6.0)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 56.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.1.0-py3-none-any.whl (10 kB)\n",
      "Collecting rsa<4.1,>=3.1.4\n",
      "  Downloading rsa-4.0-py2.py3-none-any.whl (38 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.9)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (1.24.3)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (2020.4.5.1)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard) (3.1.0)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 11.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "\u001b[K     |████████████████████████████████| 147 kB 55.9 MB/s eta 0:00:01\n",
      "\u001b[?25h\u001b[31mERROR: tensorflow-gpu 1.14.0 has requirement tensorboard<1.15.0,>=1.14.0, but you'll have tensorboard 2.2.1 which is incompatible.\u001b[0m\n",
      "Installing collected packages: tensorboard-plugin-wit, pyasn1, pyasn1-modules, cachetools, rsa, google-auth, oauthlib, requests-oauthlib, google-auth-oauthlib, tensorboard\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 1.14.0\n",
      "    Uninstalling tensorboard-1.14.0:\n",
      "      Successfully uninstalled tensorboard-1.14.0\n",
      "Successfully installed cachetools-4.1.0 google-auth-1.15.0 google-auth-oauthlib-0.4.1 oauthlib-3.1.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.0 tensorboard-2.2.1 tensorboard-plugin-wit-1.6.0.post3\n"
     ]
    }
   ],
   "source": [
    "!pip install -U tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /spell/models/model_2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /spell/models/model_2.py\n",
    "# number of epochs of training\n",
    "NUM_EPOCHS = 50\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "class BobRossSegmentedImagesDataset(Dataset):\n",
    "    def __init__(self, dataroot):        \n",
    "        super().__init__()\n",
    "        self.dataroot = dataroot\n",
    "        self.imgs = list((self.dataroot / 'train' / 'images').rglob('*.png'))\n",
    "        self.segs = list((self.dataroot / 'train' / 'labels').rglob('*.png'))\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((164, 164)),\n",
    "            transforms.Pad(46, padding_mode='reflect'),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                            mean=(0.459387, 0.46603974, 0.4336706),\n",
    "                            std=(0.06098535, 0.05802868, 0.08737113)\n",
    "            )\n",
    "        ])\n",
    "        self.color_key = {\n",
    "            3 : 0,\n",
    "            5: 1,\n",
    "            10: 2,\n",
    "            14: 3,\n",
    "            17: 4,\n",
    "            18: 5,\n",
    "            22: 6,\n",
    "            27: 7,\n",
    "            61: 8\n",
    "        }        \n",
    "        assert len(self.imgs) == len(self.segs)\n",
    "        # TODO: remean images to N(0, 1)?\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        def translate(x):\n",
    "            return self.color_key[x]\n",
    "        translate = np.vectorize(translate)\n",
    "        \n",
    "        img = Image.open(self.imgs[i])\n",
    "        img = self.transform(img)\n",
    "        \n",
    "        seg = Image.open(self.segs[i])\n",
    "        seg = seg.resize((256, 256), Image.NEAREST)\n",
    "        \n",
    "        # Labels are in the ADE20K ontology and are not consequetive,\n",
    "        # we have to apply a remap operation over the labels in a just-in-time\n",
    "        # manner. This slows things down, but it's fine, this is just a demo\n",
    "        # anyway.\n",
    "        seg = translate(np.array(seg)).astype('int64')\n",
    "        \n",
    "        # One-hot encode the segmentation mask.\n",
    "        # def ohe_mat(segmap):\n",
    "        #     return np.array(\n",
    "        #         list(\n",
    "        #             np.array(segmap) == i for i in range(9)\n",
    "        #         )\n",
    "        #     ).astype(int).reshape(9, 256, 256)\n",
    "        # seg = ohe_mat(seg)\n",
    "        \n",
    "        # Additionally, the original UNet implementation outputs a segmentation map\n",
    "        # for a subset of the overall image, not the image as a whole! With this input\n",
    "        # size the segmentation map targeted is a (164, 164) center crop.\n",
    "        seg = seg[46:210, 46:210]\n",
    "        \n",
    "        return img, seg\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_1_1 = nn.Conv2d(3, 64, 3)\n",
    "        torch.nn.init.kaiming_normal_(self.conv_1_1.weight)\n",
    "        self.relu_1_2 = nn.ReLU()\n",
    "        self.norm_1_3 = nn.BatchNorm2d(64)\n",
    "        self.conv_1_4 = nn.Conv2d(64, 64, 3)\n",
    "        torch.nn.init.kaiming_normal_(self.conv_1_4.weight)\n",
    "        self.relu_1_5 = nn.ReLU()\n",
    "        self.norm_1_6 = nn.BatchNorm2d(64)\n",
    "        self.pool_1_7 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.conv_2_1 = nn.Conv2d(64, 128, 3)\n",
    "        torch.nn.init.kaiming_normal_(self.conv_2_1.weight)        \n",
    "        self.relu_2_2 = nn.ReLU()\n",
    "        self.norm_2_3 = nn.BatchNorm2d(128)\n",
    "        self.conv_2_4 = nn.Conv2d(128, 128, 3)\n",
    "        torch.nn.init.kaiming_normal_(self.conv_2_4.weight)        \n",
    "        self.relu_2_5 = nn.ReLU()\n",
    "        self.norm_2_6 = nn.BatchNorm2d(128)\n",
    "        self.pool_2_7 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.conv_3_1 = nn.Conv2d(128, 256, 3)\n",
    "        torch.nn.init.kaiming_normal_(self.conv_3_1.weight)\n",
    "        self.relu_3_2 = nn.ReLU()\n",
    "        self.norm_3_3 = nn.BatchNorm2d(256)\n",
    "        self.conv_3_4 = nn.Conv2d(256, 256, 3)\n",
    "        torch.nn.init.kaiming_normal_(self.conv_3_4.weight)\n",
    "        self.relu_3_5 = nn.ReLU()\n",
    "        self.norm_3_6 = nn.BatchNorm2d(256)\n",
    "        self.pool_3_7 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.conv_4_1 = nn.Conv2d(256, 512, 3)\n",
    "        torch.nn.init.kaiming_normal_(self.conv_4_1.weight)\n",
    "        self.relu_4_2 = nn.ReLU()\n",
    "        self.norm_4_3 = nn.BatchNorm2d(512)\n",
    "        self.conv_4_4 = nn.Conv2d(512, 512, 3)\n",
    "        torch.nn.init.kaiming_normal_(self.conv_4_4.weight)\n",
    "        self.relu_4_5 = nn.ReLU()\n",
    "        self.norm_4_6 = nn.BatchNorm2d(512)\n",
    "        \n",
    "        # deconv is the '2D transposed convolution operator'\n",
    "        self.deconv_5_1 = nn.ConvTranspose2d(512, 256, (2, 2), 2)\n",
    "        # 61x61 -> 48x48 crop\n",
    "        self.c_crop_5_2 = lambda x: x[:, :, 6:54, 6:54]\n",
    "        self.concat_5_3 = lambda x, y: torch.cat((x, y), dim=1)\n",
    "        self.conv_5_4 = nn.Conv2d(512, 256, 3)\n",
    "        torch.nn.init.kaiming_normal_(self.conv_5_4.weight)        \n",
    "        self.relu_5_5 = nn.ReLU()\n",
    "        self.norm_5_6 = nn.BatchNorm2d(256)\n",
    "        self.conv_5_7 = nn.Conv2d(256, 256, 3)\n",
    "        torch.nn.init.kaiming_normal_(self.conv_5_7.weight)\n",
    "        self.relu_5_8 = nn.ReLU()\n",
    "        self.norm_5_9 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.deconv_6_1 = nn.ConvTranspose2d(256, 128, (2, 2), 2)\n",
    "        # 121x121 -> 88x88 crop\n",
    "        self.c_crop_6_2 = lambda x: x[:, :, 17:105, 17:105]\n",
    "        self.concat_6_3 = lambda x, y: torch.cat((x, y), dim=1)\n",
    "        self.conv_6_4 = nn.Conv2d(256, 128, 3)\n",
    "        torch.nn.init.kaiming_normal_(self.conv_6_4.weight)\n",
    "        self.relu_6_5 = nn.ReLU()\n",
    "        self.norm_6_6 = nn.BatchNorm2d(128)\n",
    "        self.conv_6_7 = nn.Conv2d(128, 128, 3)\n",
    "        torch.nn.init.kaiming_normal_(self.conv_6_7.weight)\n",
    "        self.relu_6_8 = nn.ReLU()\n",
    "        self.norm_6_9 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.deconv_7_1 = nn.ConvTranspose2d(128, 64, (2, 2), 2)\n",
    "        # 252x252 -> 168x168 crop\n",
    "        self.c_crop_7_2 = lambda x: x[:, :, 44:212, 44:212]\n",
    "        self.concat_7_3 = lambda x, y: torch.cat((x, y), dim=1)\n",
    "        self.conv_7_4 = nn.Conv2d(128, 64, 3)\n",
    "        torch.nn.init.kaiming_normal_(self.conv_7_4.weight)\n",
    "        self.relu_7_5 = nn.ReLU()\n",
    "        self.norm_7_6 = nn.BatchNorm2d(64)\n",
    "        self.conv_7_7 = nn.Conv2d(64, 64, 3)\n",
    "        torch.nn.init.kaiming_normal_(self.conv_7_7.weight)        \n",
    "        self.relu_7_8 = nn.ReLU()\n",
    "        self.norm_7_9 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        # 1x1 conv ~= fc; n_classes = 9\n",
    "        self.conv_8_1 = nn.Conv2d(64, 9, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_1_1(x)\n",
    "        x = self.relu_1_2(x)\n",
    "        x = self.norm_1_3(x)\n",
    "        x = self.conv_1_4(x)\n",
    "        x = self.relu_1_5(x)\n",
    "        x_residual_1 = self.norm_1_6(x)\n",
    "        x = self.pool_1_7(x_residual_1)\n",
    "        \n",
    "        x = self.conv_2_1(x)\n",
    "        x = self.relu_2_2(x)\n",
    "        x = self.norm_2_3(x)\n",
    "        x = self.conv_2_4(x)\n",
    "        x = self.relu_2_5(x)\n",
    "        x_residual_2 = self.norm_2_6(x)\n",
    "        x = self.pool_2_7(x_residual_2)\n",
    "        \n",
    "        x = self.conv_3_1(x)\n",
    "        x = self.relu_3_2(x)\n",
    "        x = self.norm_3_3(x)\n",
    "        x = self.conv_3_4(x)\n",
    "        x = self.relu_3_5(x)\n",
    "        x_residual_3 = self.norm_3_6(x)\n",
    "        x = self.pool_3_7(x_residual_3)\n",
    "        \n",
    "        x = self.conv_4_1(x)\n",
    "        x = self.relu_4_2(x)\n",
    "        x = self.norm_4_3(x)        \n",
    "        x = self.conv_4_4(x)\n",
    "        x = self.relu_4_5(x)\n",
    "        x = self.norm_4_6(x)\n",
    "        \n",
    "        x = self.deconv_5_1(x)\n",
    "        x = self.concat_5_3(self.c_crop_5_2(x_residual_3), x)\n",
    "        x = self.conv_5_4(x)\n",
    "        x = self.relu_5_5(x)\n",
    "        x = self.norm_5_6(x)\n",
    "        x = self.conv_5_7(x)\n",
    "        x = self.relu_5_8(x)\n",
    "        x = self.norm_5_9(x)\n",
    "        \n",
    "        x = self.deconv_6_1(x)\n",
    "        x = self.concat_6_3(self.c_crop_6_2(x_residual_2), x)\n",
    "        x = self.conv_6_4(x)\n",
    "        x = self.relu_6_5(x)\n",
    "        x = self.norm_6_6(x)\n",
    "        x = self.conv_6_7(x)\n",
    "        x = self.relu_6_8(x)\n",
    "        x = self.norm_6_9(x)\n",
    "        \n",
    "        x = self.deconv_7_1(x)\n",
    "        x = self.concat_7_3(self.c_crop_7_2(x_residual_1), x)\n",
    "        x = self.conv_7_4(x)\n",
    "        x = self.relu_7_5(x)\n",
    "        x = self.norm_7_6(x)\n",
    "        x = self.conv_7_7(x)\n",
    "        x = self.relu_7_8(x)\n",
    "        x = self.norm_7_9(x)\n",
    "        \n",
    "        x = self.conv_8_1(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "dataroot = Path('/mnt/segmented-bob-ross-images/')\n",
    "dataset = BobRossSegmentedImagesDataset(dataroot)\n",
    "dataloader = DataLoader(dataset, shuffle=True, batch_size=8)\n",
    "\n",
    "writer = SummaryWriter(f'/spell/tensorboards/model_1')\n",
    "\n",
    "model = UNet()\n",
    "model.cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    losses = []\n",
    "\n",
    "    for i, (batch, segmap) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        batch = batch.cuda()\n",
    "        segmap = segmap.cuda()\n",
    "\n",
    "        output = model(batch)\n",
    "        loss = criterion(output, segmap)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        curr_loss = loss.item()\n",
    "        if i % 10 == 0:\n",
    "            print(\n",
    "                f'Finished epoch {epoch}, batch {i}. Loss: {curr_loss:.3f}.'\n",
    "            )\n",
    "\n",
    "        writer.add_scalar(\n",
    "            'training loss', curr_loss, epoch * len(dataloader) + i\n",
    "        )\n",
    "        losses.append(curr_loss)\n",
    "\n",
    "    print(\n",
    "        f'Finished epoch {epoch}. '\n",
    "        f'avg loss: {np.mean(losses)}; median loss: {np.min(losses)}'\n",
    "    )\n",
    "    if not os.path.exists('/spell/checkpoints/'):\n",
    "        os.mkdir('/spell/checkpoints/')\n",
    "    torch.save(model.state_dict(), f'/spell/checkpoints/model_{epoch}.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
